{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aec0bd1-13e8-474a-bfca-c2ddb1902893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import thirdparty\n",
    "from thirdparty import *\n",
    "from transformers import BertTokenizer, BartForConditionalGeneration, Text2TextGenerationPipeline\n",
    "from transformers import HfArgumentParser, TrainingArguments, Trainer, set_seed\n",
    "from datasets import load_dataset, Dataset\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86f076-4ab8-459b-b8d1-d9f36f727d44",
   "metadata": {},
   "source": [
    "# 模型导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39b3131-0a9f-4df5-8e0a-ba4cd3fe3395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/root/autodl-tmp/model/\"\n",
    "model_name =  \"bart4csc-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(model_dir,model_name))\n",
    "model = BartForConditionalGeneration.from_pretrained(os.path.join(model_dir,model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cd121-074f-47b3-a494-25b7e61b0e87",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f741e17c-9970-422e-8f3a-08221999d1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "妈 吗\n"
     ]
    }
   ],
   "source": [
    "# 进行文本纠错\n",
    "def correct_text(text, tokenizer, model):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    corrected_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "# 示例\n",
    "test_sentence = \"妈麻\"\n",
    "corrected_sentence = correct_text(test_sentence, tokenizer, model)\n",
    "print(corrected_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e15d298-136d-4221-af4e-3b6867733bc3",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4293f1d1-e0e0-4cbd-a164-fa1771df66f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(path,num,test_num):\n",
    "    index=0\n",
    "    lines=[]\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(eval(line.strip()))\n",
    "            index+=1\n",
    "            if(index == num): break\n",
    "        # lines=[eval(line.strip()) for line in f.readlines()]\n",
    "    lines=[s[0].replace(\"\\t\",\"\")+\"\\t\"+s[1].replace(\"\\t\",\"\") for s in lines]\n",
    "    return {'text':lines[test_num:num]},{'text':lines[0:test_num]}\n",
    "data1,data2=read_data(\"/root/autodl-tmp/data/text-correct/train_data\",505000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a63d00d-a33e-406c-a26f-404b920481bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(tokenizer, dataset, max_len):\n",
    "    def convert_to_features(example_batch):\n",
    "        src_texts = []\n",
    "        trg_texts = []\n",
    "        for example in example_batch['text']:\n",
    "            terms = example.split('\\t', 1)\n",
    "            src_texts.append(terms[0])\n",
    "            trg_texts.append(terms[1])\n",
    "        input_encodings = tokenizer.batch_encode_plus(\n",
    "            src_texts,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_len,\n",
    "        )\n",
    "        target_encodings = tokenizer.batch_encode_plus(\n",
    "            trg_texts,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_len,\n",
    "        )\n",
    "\n",
    "        encodings = {\n",
    "            'input_ids': input_encodings['input_ids'],\n",
    "            'labels': target_encodings['input_ids']\n",
    "        }\n",
    "        return encodings\n",
    "    dataset = dataset.map(convert_to_features, batched=True)\n",
    "    dataset = dataset.remove_columns(['text'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e500d886-6f08-4acc-aae0-b7720f1d0929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5733fe133a434392bf8e27586cbd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8360555609f941289917e4611bd5e128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict(data1, split='train')\n",
    "train_data = tokenize_dataset(tokenizer, train_dataset,128)\n",
    "test_dataset = Dataset.from_dict(data2, split='test')\n",
    "test_data = tokenize_dataset(tokenizer, test_dataset,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7fed52b-7ef0-4685-8c7e-eacb20b8e7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 5000\n",
      "{'text': '在每一个州内各党选举疑个人\\t在每一个州内各党选举一个人'}\n",
      "{'input_ids': [101, 1762, 3680, 671, 702, 2336, 1079, 1392, 1054, 6848, 715, 4542, 702, 782, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [101, 1762, 3680, 671, 702, 2336, 1079, 1392, 1054, 6848, 715, 671, 702, 782, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(test_dataset))\n",
    "index=16550\n",
    "print(train_dataset[index])\n",
    "print(train_data[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac5523-abf1-4360-a5ec-7cc588499b2c",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a113a8a8-73da-4ef6-ad5d-5f3bc3b2c96b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7813' max='7813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7813/7813 53:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 102}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 102}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7813, training_loss=0.030877372725098717, metrics={'train_runtime': 3192.2428, 'train_samples_per_second': 156.63, 'train_steps_per_second': 2.447, 'total_flos': 3.810852864e+16, 'train_loss': 0.030877372725098717, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         # output directory 结果输出地址\n",
    "    num_train_epochs=1,          # total # of training epochs 训练总批次\n",
    "    per_device_train_batch_size=64,  # batch size per device during training 训练批大小\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation 评估批大小\n",
    "    logging_dir='./logs/rn_log',    # directory for storing logs 日志存储位置\n",
    "    learning_rate=1e-4,             # 学习率\n",
    "    save_steps=5000,# 不保存检查点\n",
    "    logging_steps=1000\n",
    ")\n",
    "trainer = Trainer(model=model,args=training_args,train_dataset=train_data,eval_dataset=test_data)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b369ac5-d99e-47c8-b9f6-5316a78b8124",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 102}\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./finetune-model/bart/\")\n",
    "torch.save(model,\"./finetune-model/bart/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d6e23-b6b2-4147-8d76-26548499e632",
   "metadata": {},
   "source": [
    "# 模型比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf8bb8d-ea89-4c41-9b68-3eee3315822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=get_device()\n",
    "model_dir = \"/root/autodl-tmp/model/\"\n",
    "model_name =  \"bart4csc-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(model_dir,model_name))\n",
    "model = BartForConditionalGeneration.from_pretrained(os.path.join(model_dir,model_name))\n",
    "model_self = torch.load(\"./finetune-model/bart/pytorch_model.bin\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1594d2fe-bbad-4dd4-9781-08811aea1a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原模型:  你 是 不 是 有 点 过 粪 了\n",
      "微调后模型:  你 是 不 是 有 点 过 了\n"
     ]
    }
   ],
   "source": [
    "def correct_text(text, tokenizer, model):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    corrected_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "# 示例\n",
    "test_sentence = \"我煤田都在认真xue\"\n",
    "corrected_sentence = correct_text(test_sentence, tokenizer, model)\n",
    "corrected_sentence_2 = correct_text(test_sentence, tokenizer, model_self)\n",
    "print(\"原模型: \",corrected_sentence)\n",
    "print(\"微调后模型: \",corrected_sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d1ac7-c27f-4ee4-bd56-6b0455223c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
